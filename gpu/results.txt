Реализация mt_bench для GPU
Алгоритм исследуемой программы является итерационным. Внутри
каждой итерации выполняется обработка массивов данных в двух блоках кода,
между которыми требуется синхронизация (зависимость от данных), что
отражено ниже.

 int i = get_global_id(0); 
 int j = get_global_id(1);
// kernel mt_kernel2d_1g
for (s=0;s<niters;s++){ // step
  // block 1, rw i,j, i+1, j+1, j+3, 0
  // intermediate synchronization
  // block 2 rw i,j
  // iteration synchronization
}

Данный код требует глобальной синхронизации, что реализуемо для
одной рабочей группы с помощью функции barrier.
Для реализации алгоритма на несколько рабочих групп необходима глобальная синхронизация и обмен данными через глобальную память.

Результаты анализа времени выполнения описаны ниже.
- Выполнение исследуемой программы происходит быстрее когда все
данные помещаются в локальной памяти и исполнение kernel функции
выполняется на одном вычислительном устройстве (одна рабочая группа (work group)).
- Выполнение исследуемой программы на нескольких вычислительных
устройствах требует обмен данными через глобальную память и
синхронизацию потоков исполнения между различными рабочими группами на
каждой итерации, в итоге время исполнения на нескольких рабочих группах больше чем на одной.

По результатам исследований можно сделать следующие выводы: итерационные алгоритмы с необходимостью глобальной синхронизации на каждой итерации эффективно не масштабируются на множество рабочих групп ( исполнительных устройств), эффективный коэффициент использования оборудования равен 7% (одна рабочая группа).
 
